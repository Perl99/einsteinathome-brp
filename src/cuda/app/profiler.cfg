# Profiler Configuration
#
# This version of the Cuda profiler supports configuration options that allow
# users to gather statistics about various events occurring in the GPU during execution. 
# These events are tracked with hardware counters on signals in the chip. 
#
# ------------------
#
#The profiler supports the following options:

timestamp              # Time stamps for kernel launches and memory transfers.
                       #  this can be used for timeline analysis.
gpustarttimestamp      # Time stamp when kernel starts execution in GPU.
#gpuendtimestamp       # Time stamp when kernel ends execution in GPU.
gridsize               # Number of blocks in a grid along the X and Y dimensions for 
                       #  a kernel launch          
threadblocksize        # Number of threads in a block along the X, Y and Z dimensions 
                       #  for a kernel launch
dynsmemperblock        # Size of dynamically allocated shared memory per block in bytes
                       # for a kernel launch
stasmemperblock        # Size of statically allocated shared memory per block in bytes
                       #  for a kernel launch
regperthread           # Number of registers used per thread for a kernel launch.
memtransferdir         # Memory transfer direction, a direction value of 0 is used for 
                       #  host->device memory copies and a value of 1 is used for device->host
                       #  memory copies.                  
memtransfersize        # Memory copy size in bytes
#memtransferhostmemtype# Host memory type (pageable or page-locked)
streamid               # Stream Id for a kernel launch

#
# ------------------
#
# The profiler supports logging of following counters during kernel execution on all architectures:

#local_load        #  Number of executed local load instructions per warp in a SM
#local_store       #  Number of executed local store instructions per warp in a SM
gld_request       #  Number of executed global load instructions per warp in a SM
gst_request       #  Number of executed global store instructions per warp in a SM
#divergent_branch  #  Number of unique branches that diverge
#branch            #  Number of unique branch instructions in program
#sm_cta_launched   #  Number of threads blocks executed on a SM

#
# ------------------
#
# The profiler supports logging of following counters during kernel execution only on GPUs with Compute Capability 1.x:

#gld_incoherent   # Non-coalesced (incoherent) global memory loads
gld_coherent      # Coalesced (coherent) global memory loads
#gld_32b          # 32-byte global memory load transactions
#gld_64b          # 64-byte global memory load transactions
#gld_128b         # 128-byte global memory load transactions
#gst_incoherent    # Non-coalesced (incoherent) global memory stores
gst_coherent      # Coalesced (coherent) global memory stores
#gst_32b          # 32-byte global memory store transactions
#gst_64b          # 64-byte global memory store transactions
#gst_128b         # 128-byte global memory store transactions
#instructions     # Instructions executed
#warp_serialize   # Number of thread warps that serialize on address conflicts 
                  #  to either shared or constant memory
#cta_launched     # Number of threads blocks executed
#prof_trigger_0X  
#prof_trigger_0Y  # Profiler triggers that can be inserted by user inside the kernel 
                  #  code for instrumenting the kernel. A total of 8 triggers from
                  #  prof_trigger_00 to prof_trigger_07 can be inserted in the code. 
                  #  The way to use prof triggers is to insert '__prof_trigger(int N)' in 
                  #  kernel code (where N is the counter number).                  

#tex_cache_hit    # Number of texture cache hits
#tex_cache_miss   # Number of texture cache miss

# Only 4 profiler counters can be monitored/profiled in a single run on GPUs with Compute Capability 1.x
#
# ------------------
#
# The profiler supports logging of following counters during kernel execution only on GPUs with Compute Capability 2.0 or higher:

#shared_load        #  Number of executed shared load instructions per warp in a SM
#shared_store       #  Number of executed shared store instructions per warp in a SM
#inst_issued        #  Number of instructions issued including replays
#inst_executed      #  Number of instructions executed, do not include replays
#warps_launched     #  Number of warps launched in a SM
#threads_launched   #  Number of threads launched in a SM
#l1_global_load_hit #  Number of global load hits in L1 cache
#l1_global_load_miss# Number of global load misses in L1 cache

# The number of counters that can be profiled in a single run depends on the specific counters selected on GPUs with Compute Capability 2.0 or higher.  
#
# ------------------
#
# Options can be commented out using the '#' character at the start of a line.
